{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3638b091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 12:03:26.523977: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import BaggingRegressor,BaggingClassifier, RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error,r2_score,roc_curve,auc\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c88869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = yf.Ticker(\"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ef36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = msft.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50368b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-03-13</th>\n",
       "      <td>0.055536</td>\n",
       "      <td>0.063703</td>\n",
       "      <td>0.055536</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>1031788800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-14</th>\n",
       "      <td>0.060980</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>308160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-17</th>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.064247</td>\n",
       "      <td>133171200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-18</th>\n",
       "      <td>0.064247</td>\n",
       "      <td>0.064792</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.062613</td>\n",
       "      <td>67766400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-19</th>\n",
       "      <td>0.062613</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.060980</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>47894400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-26</th>\n",
       "      <td>237.050003</td>\n",
       "      <td>241.449997</td>\n",
       "      <td>236.899994</td>\n",
       "      <td>237.449997</td>\n",
       "      <td>27694200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-27</th>\n",
       "      <td>239.979996</td>\n",
       "      <td>241.800003</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>236.410004</td>\n",
       "      <td>27018700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-28</th>\n",
       "      <td>236.809998</td>\n",
       "      <td>242.330002</td>\n",
       "      <td>234.729996</td>\n",
       "      <td>241.070007</td>\n",
       "      <td>29029700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-29</th>\n",
       "      <td>238.889999</td>\n",
       "      <td>239.949997</td>\n",
       "      <td>234.410004</td>\n",
       "      <td>237.500000</td>\n",
       "      <td>27484200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-30</th>\n",
       "      <td>238.289993</td>\n",
       "      <td>240.539993</td>\n",
       "      <td>232.729996</td>\n",
       "      <td>232.899994</td>\n",
       "      <td>35671100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9214 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close      Volume  \\\n",
       "Date                                                                     \n",
       "1986-03-13    0.055536    0.063703    0.055536    0.060980  1031788800   \n",
       "1986-03-14    0.060980    0.064247    0.060980    0.063158   308160000   \n",
       "1986-03-17    0.063158    0.064792    0.063158    0.064247   133171200   \n",
       "1986-03-18    0.064247    0.064792    0.062069    0.062613    67766400   \n",
       "1986-03-19    0.062613    0.063158    0.060980    0.061524    47894400   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2022-09-26  237.050003  241.449997  236.899994  237.449997    27694200   \n",
       "2022-09-27  239.979996  241.800003  234.500000  236.410004    27018700   \n",
       "2022-09-28  236.809998  242.330002  234.729996  241.070007    29029700   \n",
       "2022-09-29  238.889999  239.949997  234.410004  237.500000    27484200   \n",
       "2022-09-30  238.289993  240.539993  232.729996  232.899994    35671100   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "1986-03-13        0.0           0.0  \n",
       "1986-03-14        0.0           0.0  \n",
       "1986-03-17        0.0           0.0  \n",
       "1986-03-18        0.0           0.0  \n",
       "1986-03-19        0.0           0.0  \n",
       "...               ...           ...  \n",
       "2022-09-26        0.0           0.0  \n",
       "2022-09-27        0.0           0.0  \n",
       "2022-09-28        0.0           0.0  \n",
       "2022-09-29        0.0           0.0  \n",
       "2022-09-30        0.0           0.0  \n",
       "\n",
       "[9214 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23e2248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "\n",
    "class Time2Vector(Layer):\n",
    "  def __init__(self, seq_len, **kwargs):\n",
    "    super(Time2Vector, self).__init__()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) # Convert (batch, seq_len, 5) to (batch, seq_len)\n",
    "    time_linear = self.weights_linear * x + self.bias_linear\n",
    "    time_linear = tf.expand_dims(time_linear, axis=-1) # (batch, seq_len, 1)\n",
    "    \n",
    "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # (batch, seq_len, 1)\n",
    "    return tf.concat([time_linear, time_periodic], axis=-1) # (batch, seq_len, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337e7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "  def __init__(self, d_k, d_v):\n",
    "    super(SingleAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.query = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "    self.key = Dense(self.d_k, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "    self.value = Dense(self.d_v, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    q = self.query(inputs[0])\n",
    "    k = self.key(inputs[1])\n",
    "\n",
    "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "    \n",
    "    v = self.value(inputs[2])\n",
    "    attn_out = tf.matmul(attn_weights, v)\n",
    "    return attn_out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173689a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads):\n",
    "    super(MultiAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.attn_heads = list()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    for n in range(self.n_heads):\n",
    "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
    "    self.linear = Dense(7, input_shape=input_shape, kernel_initializer='glorot_uniform', bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "    concat_attn = tf.concat(attn, axis=-1)\n",
    "    multi_linear = self.linear(concat_attn)\n",
    "    return multi_linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae96f0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "    super(TransformerEncoder, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.ff_dim = ff_dim\n",
    "    self.attn_heads = list()\n",
    "    self.dropout_rate = dropout\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "    self.attn_dropout = Dropout(self.dropout_rate)\n",
    "    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "    self.ff_conv1D_2 = Conv1D(filters=7, kernel_size=1) # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
    "    self.ff_dropout = Dropout(self.dropout_rate)\n",
    "    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    attn_layer = self.attn_multi(inputs)\n",
    "    attn_layer = self.attn_dropout(attn_layer)\n",
    "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "    ff_layer = self.ff_dropout(ff_layer)\n",
    "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "    return ff_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84cadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
